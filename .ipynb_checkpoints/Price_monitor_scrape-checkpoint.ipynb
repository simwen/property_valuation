{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaeafaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb96a16",
   "metadata": {},
   "source": [
    "### First Scraper\n",
    "\n",
    "**Loops through all n rightmove results pages extracting link, price and id of each property.**\n",
    "\n",
    "1. First we define the parameters of our search i.e. the max/min price and the radius around the station.\n",
    "2. Next, since the URL changes for page 1 vs pages 2+, we reconfigure the request accordingly using `if` and `elif`. The URLs have the parameters of our search inserted. \n",
    "3. Requests.get fetches the specified webpage. r objects have `.text` attributes which returns the webpage's raw html.\n",
    "4. BeautifulSoup is a package which parses html and returns a `soup` object.\n",
    "5. `find_all` takes a html tag as an argument (\"div\" here). Any argument that’s not recognized (e.g. class_) will be turned into a filter on a tag’s attributes. Here the argument class_, is used to filter against each tag’s 'class_' attribute which identifies a new property.\n",
    "6. Looping through the apartments, we extract the relevant information this time using `find` and looking for the relevant info indicated by 'class_' again.\n",
    "7. Appending the info at the end of each loop means we compile all the info across the webpages.\n",
    "\n",
    "https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=STATION%5E6095&maxPrice=800000&minPrice=400000&radius=3.0&sortType=6&index=24&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&secondaryDisplayPropertyType=housesandflats&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=\n",
    "\n",
    "Scrape 200 properties (i.e. 8 pages as there are 25 properties per page)\n",
    "Apply filters to show properties that are: a) 2 beds, b) 1 bathroom, c) posted in last 7 days, d) a house/flat/apartment, e) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b1e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "![alt text](imagename.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aacd6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the rightmove property search results webpages \n",
    "# Collates valid properties' weblinks, plus their price and id\n",
    "\n",
    "def scrape_results_page(min_beds=2,max_beds=2,radius=1,noPages=2,days_since_added=7):\n",
    "    all_apartment_links = [] # stores apartment links\n",
    "    all_price = [] # stores the listing price of apartment\n",
    "    all_id_no = []\n",
    "    stations = ['STATION%5E7832','STATION%5E3509', 'STATION%5E9338', 'STATION%5E245']\n",
    "    \n",
    "    for station in stations:\n",
    "        for i in range(noPages):\n",
    "            if i==0:\n",
    "                r= requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier={station}&maxBedrooms={max_beds}&minBedrooms={min_beds}&radius={radius}&sortType=6&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&maxDaysSinceAdded={days_since_added}&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "            else:\n",
    "                r = ''\n",
    "                while r == '':\n",
    "                    try:\n",
    "                        r = requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier={station}&maxBedrooms={max_beds}&minBedrooms={min_beds}&radius={radius}&sortType=6&index={i*24}&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&maxDaysSinceAdded={days_since_added}&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "                        break\n",
    "                    except:\n",
    "                        print(f'Connection refused by the server on page {i+1}... sleeping for 3 seconds')\n",
    "                        time.sleep(3)\n",
    "                        print(\"Was a nice sleep, now let me continue...\")\n",
    "                        continue\n",
    "\n",
    "            soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "            apartments = soup.find_all(\"div\", class_=\"l-searchResult is-list\")\n",
    "\n",
    "            for j in range(len(apartments)):\n",
    "\n",
    "                # tracks which apartment we are on in the page\n",
    "                apartment_no = apartments[j]\n",
    "\n",
    "                # append link\n",
    "                apartment_info = apartment_no.find(\"a\", class_=\"propertyCard-link\")\n",
    "                link = \"https://www.rightmove.co.uk\" + apartment_info.attrs[\"href\"]\n",
    "                all_apartment_links.append(link)\n",
    "\n",
    "                # append price\n",
    "                price = (\n",
    "                    apartment_no.find(\"div\", class_=\"propertyCard-priceValue\")\n",
    "                    .get_text()\n",
    "                    .strip()\n",
    "                )\n",
    "                all_price.append(int(price.replace(\",\",\"\").replace(\"£\",\"\")))\n",
    "\n",
    "                # append id\n",
    "                id_no = (\n",
    "                    apartment_no.find(\"div\", id_=\"property-*\")\n",
    "                    #.get_text()\n",
    "                    #.strip()\n",
    "                )\n",
    "                all_id_no.append(id_no)\n",
    "    \n",
    "    remove_indices = [0,25]\n",
    "    all_apartment_links = [i for j, i in enumerate(all_apartment_links) if j not in remove_indices]\n",
    "    all_price = [i for j, i in enumerate(all_price) if j not in remove_indices]\n",
    "    all_id_no = [i for j, i in enumerate(all_id_no) if j not in remove_indices]\n",
    "    \n",
    "    return r.ok, all_apartment_links, all_price, all_id_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78b80189",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = scrape_results_page()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "332b731c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
