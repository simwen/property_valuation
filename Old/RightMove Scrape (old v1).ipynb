{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95458cef",
   "metadata": {},
   "source": [
    "## RightMove Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e10882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d488de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "index = 2\n",
    "\n",
    "#r1= requests.get('https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=OUTCODE%5E1864&minPrice=550000&propertyTypes=&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "#r3= requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?includeSSTC=false&keywords=&sortType=2&minPrice={minPrice}&viewType=LIST&channel=BUY&index=0&maxPrice={maxPrice}&radius=0.5&locationIdentifier=OUTCODE%5E1864')\n",
    "#r2= requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=STATION%5E6095&maxPrice={maxPrice}&minPrice={minPrice}&radius={radius}&index=24&propertyTypes=&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "#r3= requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=STATION%5E6095&maxPrice={maxPrice}&minPrice={minPrice}&radius={radius}&index={index*24}&propertyTypes=&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb96a16",
   "metadata": {},
   "source": [
    "### Main Webscraper\n",
    "\n",
    "**Loops through all n rightmove pages extracting details of each property.**\n",
    "\n",
    "1. First we define the parameters of our search i.e. the max/min price and the radius around the station.\n",
    "2. Next, since the URL changes for page 1 vs pages 2+, we reconfigure the request accordingly using `if` and `elif`. The URLs have the parameters of our search inserted. \n",
    "3. Requests.get fetches the specified webpage. r objects have `.text` attributes which returns the webpage's raw html.\n",
    "4. BeautifulSoup is a package which parses html and returns a `soup` object.\n",
    "5. `find_all` takes a html tag as an argument (\"div\" here). Any argument that’s not recognized (e.g. class_) will be turned into a filter on a tag’s attributes. Here the argument class_, is used to filter against each tag’s 'class_' attribute which identifies a new property.\n",
    "6. Looping through the apartments, we extract the relevant information this time using `find` and looking for the relevant info indicated by 'class_' again.\n",
    "7. Appending the info at the end of each loop means we compile all the info across the webpages.\n",
    "\n",
    "https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=STATION%5E6095&maxPrice=800000&minPrice=400000&radius=3.0&sortType=6&index=24&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&secondaryDisplayPropertyType=housesandflats&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacd6953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "all_apartment_links = [] # stores apartment links\n",
    "all_description = [] # stores number of bedrooms in the apartment\n",
    "all_address = [] # stores address of apartment\n",
    "all_price = [] # stores the listing price of apartment\n",
    "all_id_no = []\n",
    "\n",
    "minPrice=450000\n",
    "maxPrice=800000\n",
    "radius=3\n",
    "\n",
    "for i in range(42):\n",
    "    if i==0:\n",
    "        r= requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=STATION%5E7658&maxPrice={maxPrice}&minPrice={minPrice}&radius={radius}&sortType=6&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&secondaryDisplayPropertyType=housesandflats&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "    else:\n",
    "        r = ''\n",
    "        while r == '':\n",
    "            try:\n",
    "                r = requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=STATION%5E7658&maxPrice={maxPrice}&minPrice={minPrice}&radius={radius}&sortType=6&index={i*24}&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&secondaryDisplayPropertyType=housesandflats&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "                break\n",
    "            except:\n",
    "                print(f'Connection refused by the server on page {i+1}... sleeping for 3 seconds')\n",
    "                time.sleep(3)\n",
    "                print(\"Was a nice sleep, now let me continue...\")\n",
    "                continue\n",
    "        #r= requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=STATION%5E6095&maxPrice={maxPrice}&minPrice={minPrice}&radius={radius}&sortType=6&index={i*24}&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&secondaryDisplayPropertyType=housesandflats&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    \n",
    "    apartments = soup.find_all(\"div\", class_=\"l-searchResult is-list\")\n",
    "    \n",
    "    for i in range(len(apartments)):\n",
    "\n",
    "        # tracks which apartment we are on in the page\n",
    "        apartment_no = apartments[i]\n",
    "\n",
    "        # append link\n",
    "        apartment_info = apartment_no.find(\"a\", class_=\"propertyCard-link\")\n",
    "        link = \"https://www.rightmove.co.uk\" + apartment_info.attrs[\"href\"]\n",
    "        all_apartment_links.append(link)\n",
    "\n",
    "        # append address\n",
    "        address = (\n",
    "            apartment_info.find(\"address\", class_=\"propertyCard-address\")\n",
    "            .get_text()\n",
    "            .strip()\n",
    "        )\n",
    "        all_address.append(address)\n",
    "\n",
    "        # append description\n",
    "        description = (\n",
    "            apartment_info.find(\"h2\", class_=\"propertyCard-title\")\n",
    "            .get_text()\n",
    "            .strip()\n",
    "        )\n",
    "        all_description.append(description)\n",
    "\n",
    "        # append price\n",
    "        price = (\n",
    "            apartment_no.find(\"div\", class_=\"propertyCard-priceValue\")\n",
    "            .get_text()\n",
    "            .strip()\n",
    "        )\n",
    "        all_price.append(price)\n",
    "        \n",
    "        # append id\n",
    "        id_no = (\n",
    "            apartment_no.find(\"div\", id_=\"property-*\")\n",
    "            #.get_text()\n",
    "            #.strip()\n",
    "        )\n",
    "        all_id_no.append(id_no)\n",
    "\n",
    "r.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd00eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links =[]\n",
    "all_features =[]\n",
    "all_prices =[]\n",
    "all_statname =[]\n",
    "all_statdist =[]\n",
    "all_outcodes = []\n",
    "all_postcodes = []\n",
    "all_centralities = []\n",
    "\n",
    "import re\n",
    "import json\n",
    "import geopy\n",
    "from geopy import distance\n",
    "\n",
    "for i in range(len(all_apartment_links)):\n",
    "    r= requests.get(all_apartment_links[i])\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    \n",
    "    # Append variables of interest\n",
    "    \n",
    "    # weblink\n",
    "    all_links.append(all_apartment_links[i])\n",
    "    \n",
    "    # physical features\n",
    "    features = (\n",
    "        soup.find_all(\"p\", class_=\"_1hV1kqpVceE9m-QrX_hWDN\")\n",
    "    )\n",
    "    features =[str(i).replace('<p class=\"_1hV1kqpVceE9m-QrX_hWDN\">', '').replace('</p>', '')\n",
    "     .replace('<p class=\"_1hV1kqpVceE9m-QrX_hWDN _2SpNNVW0fTYoFvPDmhKSt8 _3ixAp8byA3wC3qvii8d-kg\">' , '') \n",
    "     for i in features]\n",
    "    features =[i for i in features if \"<p class\" not in i ]\n",
    "    all_features.append(features)\n",
    "    \n",
    "    # price\n",
    "    price = (\n",
    "        soup.find('input').attrs['value']\n",
    "        #.get_text()\n",
    "        #.strip()\n",
    "    )\n",
    "    all_prices.append(int(price.replace(\",\",\"\")))\n",
    "    \n",
    "    # postcodes   \n",
    "    links = soup.find_all('script')[4]    \n",
    "    jsonobj = json.loads(links.text[25:]) # converts json into dictionary  \n",
    "    outcode = jsonobj.get(\"propertyData\").get('address').get('outcode')\n",
    "    postcode = outcode + jsonobj.get(\"propertyData\").get('address').get('incode')\n",
    "    all_outcodes.append(outcode)\n",
    "    all_postcodes.append(postcode)    \n",
    "    \n",
    "    # distance to centre of London\n",
    "    latitude = float(jsonobj.get(\"propertyData\").get('location').get('latitude'))\n",
    "    longitude = float(jsonobj.get(\"propertyData\").get('location').get('longitude'))\n",
    "    coords = (latitude, longitude)\n",
    "    charingX = (51.507602, -0.127816)\n",
    "    centrality = geopy.distance.geodesic(coords, charingX).km\n",
    "    all_centralities.append(centrality)\n",
    "    \n",
    "    # stations\n",
    "    statdist = (\n",
    "        soup.find(\"span\", class_=\"_1ZY603T1ryTT3dMgGkM7Lg\")\n",
    "        .get_text()\n",
    "        .strip()\n",
    "    )\n",
    "    all_statdist.append(float(statdist.replace(\" miles\",\"\")))\n",
    "    \n",
    "    statname = (\n",
    "        soup.find(\"span\", class_=\"cGDiWU3FlTjqSs-F1LwK4\")\n",
    "        .get_text()\n",
    "        .strip()\n",
    "    )\n",
    "    all_statname.append(statname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc445754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating property type variable\n",
    "prop_type =[]\n",
    "\n",
    "for i in all_features:\n",
    "    if i[0] in ('Apartment','Flat','Studio','Maisonette', 'House','Terraced','Mews'):\n",
    "        prop_type.append(i[0])\n",
    "    else: \n",
    "        prop_type.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bedrooms & bathrooms variable\n",
    "bedrooms =[]\n",
    "bathrooms =[]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for i in all_features:\n",
    "    if i[0] == 'Studio':\n",
    "        bedrooms.append(0)\n",
    "        if i[1].startswith('×'):\n",
    "            bathrooms.append(int(i[1][1]))\n",
    "        else:\n",
    "            bathrooms.append(np.nan)\n",
    "    elif i[0].startswith('×') and i[1].startswith('×'): \n",
    "        bedrooms.append(int(i[0][1]))\n",
    "        bathrooms.append(int(i[1][1]))\n",
    "    elif len(i) <= 2:\n",
    "        bedrooms.append(np.nan)\n",
    "        bathrooms.append(np.nan)  \n",
    "    elif i[1].startswith('×') and i[2].startswith('×'): \n",
    "        bedrooms.append(int(i[1][1]))\n",
    "        bathrooms.append(int(i[2][1]))  \n",
    "    else:\n",
    "        bedrooms.append(np.nan)\n",
    "        bathrooms.append(np.nan)\n",
    "\n",
    "bedrooms[:20] \n",
    "#bathrooms[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating floor size (sq. ft.) variable\n",
    "\n",
    "import re\n",
    "floor_size =[]\n",
    "\n",
    "for i in range(len(all_features)):\n",
    "    for j in range(len(all_features[i])):\n",
    "        if all_features[i][j].endswith('sq. ft.'):\n",
    "            clean1 = int(re.sub(\"[^0-9]\", \"\", all_features[i][j]))\n",
    "            if len(str(clean1)) > 4:   # Fixes instances where floor size is a range (e.g. 439-1051 sq feet)\n",
    "                clean1 = str(clean1)\n",
    "                half = int(len(clean1)/2)\n",
    "                clean1 = int( (int(clean1[0:half]) + int(clean1[half:len(clean1)]) ) / 2)\n",
    "            elif clean1 > 3000:  # Remove floorsizes > 3000\n",
    "                clean1 = np.nan\n",
    "            floor_size.append(clean1)\n",
    "    if len(floor_size) <= i: \n",
    "        floor_size.append(np.nan)\n",
    "floor_size[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating contract type variable\n",
    "\n",
    "contract =[]\n",
    "\n",
    "for i in all_features:\n",
    "    if i[-1] == 'Leasehold':\n",
    "        contract.append('Leasehold')\n",
    "    elif i[-1] == 'Share of Freehold':\n",
    "        contract.append('Freehold')\n",
    "    else:\n",
    "        contract.append('')\n",
    "\n",
    "contract[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new outcode variable\n",
    "\n",
    "outcode2 =[]\n",
    "\n",
    "for i in all_outcodes:\n",
    "    if i[-1].isalpha() == True:\n",
    "        outcode2.append(i[0:-1])\n",
    "    else:\n",
    "        outcode2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "data = {\"Links\": all_links,\n",
    "    \"Price\": all_prices,\n",
    "    \"NearStat\": all_statname,\n",
    "    \"StatDist(miles)\": all_statdist,\n",
    "    \"Prop_Type\": prop_type,\n",
    "    \"Bedrooms\": bedrooms,\n",
    "    \"Bathrooms\": bathrooms,\n",
    "    \"Floor_Size\": floor_size,\n",
    "    \"Contract_Type\": contract,\n",
    "    \"Outcode\": all_outcodes,\n",
    "    \"Outcode2\": outcode2,\n",
    "    \"Postcode\": all_postcodes,\n",
    "    \"Centrality\": all_centralities\n",
    "       }\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Floor_Size']>1500]\n",
    "df.iloc[57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68c610",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NearStat'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outcode2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7df6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Outcode'].value_counts()) - len(df['Outcode2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting dummies vars\n",
    "df2 = pd.concat([df, pd.get_dummies(df.iloc[:,4])], axis=1) #prop_type\n",
    "df2 = pd.concat([df2, pd.get_dummies(df.iloc[:,2])], axis=1) #nearest station\n",
    "df2 = pd.concat([df2, pd.get_dummies(df.iloc[:,8])], axis=1) #contract\n",
    "df2 = pd.concat([df2, pd.get_dummies(df.iloc[:,9])], axis=1) #outcode\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044b10a",
   "metadata": {},
   "source": [
    "### Variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave out 'Studio', 'Freehold', 'Regent\\'s Park Station', 'Great Portland Street Station', W1W, W1U, W1T, W1G, W1B, W1K\n",
    "variables = ['Price','StatDist(miles)','Bedrooms','Bathrooms','Apartment','Flat','House','Maisonette','Mews','Terraced','Leasehold','W2', 'NW8', 'NW1', 'W9', 'W1H']\n",
    "stations = ['Edgware Road (Circle, District, Hammersmith & City) Station',\n",
    "'St. John\\'s Wood Station','Marylebone Station','Paddington Station',                                             \n",
    "'Edgware Road (Bakerloo) Station', 'Warwick Avenue Station','Lancaster Gate Station',\n",
    "'Marble Arch Station','Maida Vale Station',\n",
    "'Baker Street Station','Royal Oak Station']\n",
    "\n",
    "df_varselect = df2[variables]\n",
    "df_varselect2 =df2[stations]\n",
    "df_varselect2 = pd.concat([df_varselect, df_varselect2], axis=1).dropna()\n",
    "df_varselect2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array(df_varselect2.iloc[:,1:df_varselect2.shape[1]])\n",
    "y = np.array(df_varselect2.iloc[:,0])\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d9a7c",
   "metadata": {},
   "source": [
    "### With floor size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_varselect3 = df2[variables]\n",
    "df_varselect4 =df2[stations[0:7]]\n",
    "df_varselect4 = pd.concat([df_varselect3, df_varselect4, df2['Floor_Size']], axis=1).dropna()\n",
    "df_varselect4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336803d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_varselect4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 is much higher when including floor size\n",
    "X = np.array(df_varselect4.iloc[:,1:df_varselect4.shape[1]])\n",
    "y = np.array(df_varselect4.iloc[:,0])\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = df_varselect4['Floor_Size']\n",
    "y = df_varselect4['Price']\n",
    "a, b, c = np.polyfit(x, y, 2)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = plt.axes()\n",
    "ax.scatter(x,y)\n",
    "\n",
    "x2 = np.linspace(min(x), max(x), len(x))\n",
    "y2 = a*(x2**2) + b*x2 + c\n",
    "ax.plot(x2, y2)\n",
    "\n",
    "ax.set_xlabel('Floor Size (sq. ft.)')\n",
    "ax.set_ylabel('Price (£)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fb251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
